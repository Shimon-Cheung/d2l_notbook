{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 读取文件\n",
    "到目前为止，我们讨论了如何处理数据， 以及如何构建、训练和测试深度学习模型。 然而，有时我们希望保存训练的模型， 以备将来在各种环境中使用（比如在部署中进行预测）。 此外，当运行一个耗时较长的训练过程时， 最佳的做法是定期保存中间结果， 以确保在服务器电源被不小心断掉时，我们不会损失几天的计算结果。 因此，现在是时候学习如何加载和存储权重向量和整个模型了."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (644481850.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn [1], line 2\u001B[1;36m\u001B[0m\n\u001B[1;33m    到目前为止，我们讨论了如何处理数据， 以及如何构建、训练和测试深度学习模型。 然而，有时我们希望保存训练的模型， 以备将来在各种环境中使用（比如在部署中进行预测）。 此外，当运行一个耗时较长的训练过程时， 最佳的做法是定期保存中间结果， 以确保在服务器电源被不小心断掉时，我们不会损失几天的计算结果。 因此，现在是时候学习如何加载和存储权重向量和整个模型了。\u001B[0m\n\u001B[1;37m                     ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid character in identifier\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 加载和保存张量\n",
    "对于单个张量，我们可以直接调用load和save函数分别读写它们。 这两个函数都要求我们提供一个名称，save要求将要保存的变量作为输入."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "X = torch.arange(4)\n",
    "torch.save(X, \"x-file\")  # 这里把tensor存储在一个x-file文件里面去了"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 1, 2, 3])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = torch.load(\"x-file\")\n",
    "X2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们可以存储一个张量列表，然后把它们读回内存."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.zeros(4)\n",
    "torch.save([X, y], 'x-files')\n",
    "x2, y2 = torch.load('x-files')\n",
    "(x2, y2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们甚至可以写入或读取从字符串映射到张量的字典。 当我们要读取或写入模型中的所有权重时，这很方便."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'x': X, 'y': y}\n",
    "torch.save(mydict, 'mydict')\n",
    "mydict2 = torch.load('mydict')\n",
    "mydict2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 加载和保存模型参数\n",
    "保存单个权重向量（或其他张量）确实有用， 但是如果我们想保存整个模型，并在以后加载它们， 单独保存每个向量则会变得很麻烦。 毕竟，我们可能有数百个参数散布在各处。 因此，深度学习框架提供了内置函数来保存和加载整个网络。 需要注意的一个重要细节是，这将保存模型的参数而不是保存整个模型。 例如，如果我们有一个3层多层感知机，我们需要单独指定架构。 因为模型本身可以包含任意代码，所以模型本身难以序列化。 因此，为了恢复模型，我们需要用代码生成架构， 然后从磁盘加载参数。 让我们从熟悉的多层感知机开始尝试一下."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.1085,  0.1417,  0.2134,  0.2068, -0.2014, -0.3325,  0.2564, -0.5923,\n          0.4699,  0.4347],\n        [ 0.2589,  0.2976,  0.0605,  0.0982,  0.0279,  0.0738,  0.5542, -0.2274,\n         -0.3917,  0.2662]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)\n",
    "Y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('hidden.weight', tensor([[-0.1014,  0.1417, -0.0447,  ...,  0.0135, -0.1956,  0.1955],\n",
      "        [ 0.1148,  0.2112,  0.1328,  ..., -0.1867,  0.1975,  0.1691],\n",
      "        [ 0.1829,  0.0598, -0.1995,  ...,  0.2206, -0.0421, -0.1358],\n",
      "        ...,\n",
      "        [ 0.1249, -0.1580,  0.1091,  ..., -0.0683, -0.1282,  0.0350],\n",
      "        [ 0.0046,  0.1626,  0.0397,  ..., -0.0745, -0.1028, -0.0781],\n",
      "        [-0.0239,  0.1306, -0.0634,  ..., -0.0030, -0.0672,  0.0437]])), ('hidden.bias', tensor([-0.2118,  0.1263, -0.1646, -0.0561,  0.1569, -0.1508,  0.1469,  0.1548,\n",
      "        -0.1512,  0.0367,  0.0783, -0.0448, -0.0299,  0.0290, -0.0511,  0.0187,\n",
      "         0.1260,  0.1338,  0.0521,  0.0623,  0.2113, -0.1623,  0.0331,  0.0414,\n",
      "        -0.1237, -0.1799,  0.1858, -0.0786,  0.0405, -0.1113, -0.2020, -0.1152,\n",
      "         0.2016,  0.1969, -0.0233,  0.0775,  0.1428, -0.2088, -0.1377,  0.1641,\n",
      "         0.0493, -0.2212,  0.1530,  0.0355,  0.1827,  0.1306,  0.1763,  0.0499,\n",
      "         0.1425,  0.0370, -0.0386, -0.0917, -0.1506,  0.1848,  0.1068, -0.0255,\n",
      "         0.1257,  0.0237,  0.1963,  0.0044,  0.0099, -0.0479, -0.1693,  0.1000,\n",
      "        -0.0513,  0.1658,  0.2086,  0.1536, -0.0971,  0.1178, -0.0759, -0.1288,\n",
      "         0.1947,  0.1804, -0.1318, -0.0784, -0.0503, -0.1907, -0.1633,  0.2140,\n",
      "         0.0931, -0.1510, -0.1853, -0.1678,  0.0147, -0.0103,  0.1749, -0.0786,\n",
      "        -0.1931,  0.1008, -0.0810,  0.1710, -0.0802,  0.0672, -0.1574,  0.1742,\n",
      "        -0.0262,  0.0511, -0.2187, -0.2048, -0.0657,  0.0612, -0.0870,  0.0373,\n",
      "         0.1134, -0.0662, -0.1133, -0.0900,  0.0131,  0.1699, -0.2165, -0.2110,\n",
      "        -0.0277,  0.1929,  0.1732,  0.0608, -0.0214, -0.0135, -0.2115, -0.1370,\n",
      "        -0.1245, -0.1224,  0.0565, -0.0316,  0.0503,  0.1913,  0.0682, -0.1576,\n",
      "         0.2125,  0.1514,  0.1200, -0.0217,  0.0724,  0.0826, -0.1045,  0.0447,\n",
      "        -0.0833, -0.0168, -0.1889, -0.2122, -0.1654, -0.1672,  0.1027, -0.0794,\n",
      "        -0.2010,  0.1769,  0.0806, -0.0746, -0.0135, -0.0733, -0.1361,  0.1788,\n",
      "         0.0965,  0.0226,  0.2187, -0.0137, -0.1216, -0.0790, -0.2067,  0.0706,\n",
      "        -0.0954, -0.1171,  0.2081, -0.1139, -0.0069, -0.0663, -0.2225, -0.0509,\n",
      "        -0.1965,  0.0972,  0.2020, -0.2141, -0.0742,  0.1483, -0.1262, -0.0682,\n",
      "         0.0184, -0.1648, -0.0751,  0.2062,  0.1244, -0.0779,  0.1916, -0.1536,\n",
      "        -0.1382,  0.1835, -0.1275, -0.1230,  0.1337,  0.1176, -0.0211,  0.0666,\n",
      "        -0.0451, -0.0095,  0.1681,  0.0892, -0.0896,  0.1513, -0.0524, -0.1403,\n",
      "        -0.0526, -0.0058, -0.0403, -0.2203, -0.1756,  0.0991, -0.0204,  0.1092,\n",
      "         0.1563,  0.1683, -0.0156,  0.0741,  0.0838, -0.0790, -0.0806, -0.0765,\n",
      "        -0.1170, -0.1909, -0.1044,  0.0134,  0.0119, -0.0511,  0.0384,  0.0639,\n",
      "         0.0635, -0.0922,  0.0826,  0.0076,  0.1314,  0.2165,  0.0247, -0.1357,\n",
      "         0.0887, -0.1722,  0.0210, -0.2117,  0.1628, -0.0677, -0.0745,  0.1915,\n",
      "         0.1894, -0.2025,  0.1693,  0.0197,  0.0925, -0.1260, -0.2096, -0.2086,\n",
      "         0.0637, -0.1702, -0.1279,  0.1630,  0.0498,  0.0304, -0.1330, -0.1189])), ('output.weight', tensor([[-4.6897e-02,  2.0370e-02, -5.9370e-02,  ..., -5.5777e-02,\n",
      "          9.9480e-05,  1.6129e-02],\n",
      "        [-4.7040e-02,  5.4458e-02,  5.0356e-02,  ...,  5.7259e-02,\n",
      "          3.7211e-02, -2.3925e-03],\n",
      "        [ 2.3559e-02,  1.0416e-02, -1.8250e-03,  ...,  3.5752e-02,\n",
      "          7.1454e-03, -3.1326e-02],\n",
      "        ...,\n",
      "        [-2.6336e-02,  5.7081e-02,  1.3974e-02,  ...,  2.7385e-02,\n",
      "         -5.0921e-02,  7.7513e-03],\n",
      "        [ 3.3414e-02, -4.5085e-02,  5.3278e-02,  ..., -6.2992e-03,\n",
      "          5.4751e-02, -9.9679e-03],\n",
      "        [ 3.5819e-02,  3.7715e-03,  1.1424e-02,  ...,  7.9735e-03,\n",
      "          4.6166e-02, -3.7677e-02]])), ('output.bias', tensor([ 0.0538,  0.0373, -0.0306,  0.0074, -0.0204,  0.0460, -0.0023,  0.0223,\n",
      "         0.0164,  0.0605]))])\n"
     ]
    }
   ],
   "source": [
    "torch.save(net.state_dict(), 'mlp.params')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "为了恢复模型，我们实例化了原始多层感知机模型的一个备份。 这里我们不需要随机初始化模型参数，而是直接读取文件中存储的参数."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "MLP(\n  (hidden): Linear(in_features=20, out_features=256, bias=True)\n  (output): Linear(in_features=256, out_features=10, bias=True)\n)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('mlp.params'))\n",
    "clone.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "由于两个实例具有相同的模型参数，在输入相同的X时， 两个实例的计算结果应该相同。 让我们来验证一下."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
